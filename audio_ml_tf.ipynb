{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build training set\n",
    "# imports\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torchvision import transforms as vt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict(py_dict,dict_key):\n",
    "    if dict_key in py_dict:\n",
    "        val = py_dict[dict_key]\n",
    "    else:\n",
    "        val = ''\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_strings(string_list, target_string):\n",
    "    # make case insensitive\n",
    "    lower_target_string = target_string.lower()\n",
    "    matching_strings = [s.lower() for s in string_list if s.lower() in lower_target_string]\n",
    "    return matching_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_list = ['Clarinet','Sax Alto','Flute','Violin','Trumpet','Cello','Sax Tenor','Piccolo','Sax Soprano','Sax Baritone','Oboe','Double Bass']\n",
    "def create_music_record(dir_path, instrument_list):\n",
    "    # find wav file\n",
    "    wav_files = glob.glob(os.path.join(dir_path, '**', '*.wav'), recursive=True)\n",
    "    # skip if more/less than 1 file found\n",
    "    if len(wav_files) == 1:\n",
    "        wav_file = wav_files[0]\n",
    "        # print(\"wav file:\", wav_file)\n",
    "    else:\n",
    "        print(f\"incorrect number of wav files found in {dir_path}\")\n",
    "        return\n",
    "    \n",
    "    # get sound_metadata \n",
    "    metadata_file = os.path.join(dir_path,'sound_metadata.pkl')\n",
    "    # print(metadata_file)\n",
    "    # check if file exists:\n",
    "    metadata_exists = os.path.isfile(metadata_file)\n",
    "    # if exists, load\n",
    "    if metadata_exists:\n",
    "        with open(metadata_file, 'rb') as file:\n",
    "            sound_metadata = pickle.load(file)\n",
    "        \n",
    "        # format metadata\n",
    "        ## parse name to get instrument and note (target variables)\n",
    "        try:\n",
    "            sound_name = sound_metadata['name']\n",
    "            # sound_name_split = sound_name.split('-')\n",
    "            # sound_instr = sound_name_split[0].strip()\n",
    "            # sound_note = sound_name_split[1].strip()\n",
    "            found_instruments = find_matching_strings(instrument_list,sound_name)\n",
    "            if len(found_instruments) == 1:\n",
    "                sound_instr = found_instruments[0]\n",
    "            else:\n",
    "                # default to blank and investigate later\n",
    "                sound_instr = ''\n",
    "        except IndexError as e:\n",
    "            sound_instr = ''\n",
    "            # sound_note = ''\n",
    "        \n",
    "        # if \"channels\" in sound_metadata:\n",
    "        #     channels = sound_metadata['channels']\n",
    "        # else:\n",
    "        #     channels = ''\n",
    "        \n",
    "        \n",
    "        music_record = {\"relative_path\":wav_file,\n",
    "                        \"channels\":check_dict(sound_metadata,\"channels\"),\n",
    "                        \"filesize\":check_dict(sound_metadata,\"filesize\"),\n",
    "                        \"bitrate\":check_dict(sound_metadata,\"bitrate\"),\n",
    "                        \"bitdepth\":check_dict(sound_metadata,\"bitdepth\"),\n",
    "                        \"duration\":check_dict(sound_metadata,\"duration\"),\n",
    "                        \"samplerate\":check_dict(sound_metadata,\"samplerate\"),\n",
    "                        \"instrument_name\":sound_instr}\n",
    "        return music_record\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# create_music_record(dir_list[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7554\n",
      "incorrect number of wav files found in ./freesound\\247146\n"
     ]
    }
   ],
   "source": [
    "def create_music_set(dir_list):\n",
    "    music_list = [create_music_record(dir_,instrument_list = instrument_list) for dir_ in dir_list] \n",
    "    # filter\n",
    "    music_fltrd = [i for i in music_list if i is not None]\n",
    "    music_df = pd.DataFrame(music_fltrd)\n",
    "    return music_df\n",
    "\n",
    "dir_list = []\n",
    "for root, dirs, files in os.walk(\"./freesound\"):\n",
    "        for directory in dirs:\n",
    "            dir_list.append(os.path.join(root,directory))\n",
    "print(len(dir_list))\n",
    "music_df = create_music_set(dir_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records missing target variable: 1. Removing  0.0% of records from our data\n"
     ]
    }
   ],
   "source": [
    "# clean up\n",
    "n_missing = music_df.loc[music_df['instrument_name'] == ''].shape[0]\n",
    "pct_missing = round(10*n_missing/music_df.shape[0],2)\n",
    "print(f\"Records missing target variable: {n_missing}. Removing  {pct_missing}% of records from our data\")\n",
    "\n",
    "\n",
    "music_df = music_df.loc[music_df['instrument_name'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerically Encode Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument_name</th>\n",
       "      <th>target_instrument</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clarinet</td>\n",
       "      <td>1</td>\n",
       "      <td>1670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>violin</td>\n",
       "      <td>11</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trumpet</td>\n",
       "      <td>10</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cello</td>\n",
       "      <td>0</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sax alto</td>\n",
       "      <td>6</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flute</td>\n",
       "      <td>3</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sax tenor</td>\n",
       "      <td>9</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>piccolo</td>\n",
       "      <td>5</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sax soprano</td>\n",
       "      <td>8</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sax baritone</td>\n",
       "      <td>7</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>oboe</td>\n",
       "      <td>4</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>double bass</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instrument_name  target_instrument  count\n",
       "0         clarinet                  1   1670\n",
       "1           violin                 11   1052\n",
       "2          trumpet                 10    829\n",
       "3            cello                  0    726\n",
       "4         sax alto                  6    717\n",
       "5            flute                  3    694\n",
       "6        sax tenor                  9    449\n",
       "7          piccolo                  5    388\n",
       "8      sax soprano                  8    334\n",
       "9     sax baritone                  7    288\n",
       "10            oboe                  4    246\n",
       "11     double bass                  2    159"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numerical encode target instrument\n",
    "encoder = LabelEncoder()\n",
    "music_df['target_instrument'] = encoder.fit_transform(music_df['instrument_name']).astype('int64')\n",
    "music_df['target_instrument'].unique()\n",
    "\n",
    "instrument_map = music_df[['instrument_name','target_instrument']].value_counts().reset_index()\n",
    "instrument_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess for transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(images, n_patches):\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    assert h == w, \"Patchify method is implemented for square images only\"\n",
    "\n",
    "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
    "    patch_size = h // n_patches\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        for i in range(n_patches):\n",
    "            for j in range(n_patches):\n",
    "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                patches[idx, i * n_patches + j] = patch.flatten()\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViT(nn.Module):\n",
    "  def __init__(self, chw=(1, 28, 28), n_patches=7):\n",
    "    # Super constructor\n",
    "    super(MyViT, self).__init__()\n",
    "\n",
    "    # Attributes\n",
    "    self.chw = chw # (C, H, W)\n",
    "    self.n_patches = n_patches\n",
    "\n",
    "    assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "    assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
    "\n",
    "  def forward(self, images):\n",
    "    patches = patchify(images, self.n_patches)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 49, 32)\n",
      "[[[-1.0461915   1.2305212   1.8662122  ...  1.1032946  -1.3344064\n",
      "   -2.581236  ]\n",
      "  [ 0.06754854  0.44813395 -0.5985899  ... -0.76082724 -0.72297764\n",
      "    0.5215839 ]\n",
      "  [ 0.21132568  0.13313377  0.25223497 ... -0.06073891 -0.8029356\n",
      "    0.06508627]\n",
      "  ...\n",
      "  [-0.88790995  0.79799265 -0.36270887 ...  1.0173298  -0.5579972\n",
      "    0.11708623]\n",
      "  [-0.59282196 -1.5264444  -0.07835507 ...  0.31156117 -0.1824684\n",
      "    1.9655087 ]\n",
      "  [-1.2054605  -0.81623    -0.9593591  ...  0.44824982  0.52507913\n",
      "   -1.6396205 ]]]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "\n",
    "  # Current model\n",
    "model = MyViT(\n",
    "  chw=(1, 28, 28),\n",
    "  n_patches=7\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 2, 28, 28) # Dummy images\n",
    "x2 = model(x).numpy()\n",
    "print(x2.shape) # torch.Size([7, 49, 16])\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 4, 7, 7)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage.util.shape import view_as_blocks\n",
    "torch.manual_seed(17)\n",
    "x = torch.randn(1,2,28, 28).numpy()\n",
    "\n",
    "x3 = view_as_blocks(x, block_shape=(1,1,7,7))\n",
    "\n",
    "x3.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0461915e+00,  1.2305212e+00,  1.8662122e+00, ...,\n",
       "         3.8504535e-01, -7.6659721e-01,  1.5816286e+00],\n",
       "       [ 2.3505518e-01,  1.2705117e+00, -4.9797949e-01, ...,\n",
       "        -9.2189276e-01,  1.3849835e+00, -1.0581790e+00],\n",
       "       [ 1.5265250e+00,  5.8004040e-01,  1.8565146e+00, ...,\n",
       "        -3.8039985e-01,  1.2446707e+00,  1.4971067e+00],\n",
       "       ...,\n",
       "       [-6.0182762e-01, -5.2705139e-01,  7.2333544e-01, ...,\n",
       "        -1.1251336e+00, -4.3829238e-01, -7.4847996e-01],\n",
       "       [ 8.6367428e-01,  1.0425885e+00, -1.1460442e-03, ...,\n",
       "        -1.1520212e+00,  1.2362085e-01,  5.3020716e-01],\n",
       "       [ 3.1318608e-01, -1.1552500e+00, -1.2039675e+00, ...,\n",
       "         1.8449354e+00,  7.2837526e-01, -1.8400691e+00]], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(17)\n",
    "x = torch.randn(1,2,64,324).numpy()\n",
    "\n",
    "x3 = view_as_blocks(x, block_shape=(1,1,8,18))\n",
    "\n",
    "x3.reshape(36,1152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41472/36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "324/18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
